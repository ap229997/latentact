# How Do I Do That? Synthesizing 3D Hand Motion and Contacts for Everyday Interactions

## [Project Page](https://ap229997.github.io/projects/latentact) | [Paper](https://ap229997.github.io/projects/latentact/assets/paper.pdf) | [Supplementary](https://ap229997.github.io/projects/latentact/assets/suppmat.pdf) | [Video]() | [Poster]()

<p align="center">
  <img src="assets/teaser.png" height="256">
</p>
<!-- <img src="assets/intercode.svg" height="192" hspace=30> <img src="assets/interpred.svg" height="192"> -->

This repository contains the code for the CVPR 2025 paper [How Do I Do That? Synthesizing 3D Hand Motion and Contacts for Everyday Interactions](https://ap229997.github.io/projects/latentact/assets/paper.pdf). If you find our code or paper useful, please cite
```bibtex
@inproceedings{Prakash2025LatentAct,
                author = {Prakash, Aditya and Lundell, Benjamin and Andreychuk, Dmitry and Forsyth, David and Gupta, Saurabh and Sawhney, Harpreet},
                title = {How Do I Do That? Synthesizing 3D Hand Motion and Contacts for Everyday Interactions},
                booktitle = {Computer Vision and Pattern Recognition (CVPR)},
                year = {2025}
            }
```

## Timeline

- [ ] Code and Data release by April 30, 2025

## License

All the material here is released under the Creative Commons Attribution-NonCommerial 4.0 International License, found [here](https://creativecommons.org/licenses/by-nc/4.0/). For all the datasets used in this work, please refer to their respective licenses.